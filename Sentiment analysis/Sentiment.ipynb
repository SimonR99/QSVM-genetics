{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quantum support vector machines for text classification\n",
    "\n",
    "The Support Vector Machine (SVM) is a widely utilized machine learning algorithm renowned for its ability to achieve high accuracy in both binary and multiclass classification tasks. The computational complexity of the SVM algorithm can be influenced by the choice of the kernel used to transform the input data into a higher-dimensional feature space.\n",
    "\n",
    "Different kernels offer varying degrees of efficacy, with some proving to be more effective than others. However, there is often a trade-off between the accuracy and the computational complexity of the kernel. For specific datasets, it may be necessary to opt for a kernel with greater complexity to discern intricate patterns within the data. In certain computational challenges, leveraging a quantum kernel has the potential to significantly reduce the required processing time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Library importation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Visualisation Imports\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Scikit Imports\n",
    "from sklearn import datasets, model_selection, naive_bayes\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Qiskit Imports\n",
    "from qiskit import Aer, execute\n",
    "from qiskit.circuit import QuantumCircuit, Parameter, ParameterVector, QuantumRegister, ClassicalRegister\n",
    "from qiskit.circuit.library import PauliFeatureMap, ZFeatureMap, ZZFeatureMap, EfficientSU2\n",
    "from qiskit.circuit.library import TwoLocal, NLocal, RealAmplitudes, EfficientSU2\n",
    "from qiskit.circuit.library import HGate, RXGate, RYGate, RZGate, CXGate, CRXGate, CRZGate, XGate\n",
    "from qiskit.circuit.library.data_preparation import StatePreparation\n",
    "from qiskit_machine_learning.kernels import QuantumKernel\n",
    "\n",
    "\n",
    "# NLP Imports\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk import pos_tag\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from collections import defaultdict\n",
    "from nltk.corpus import wordnet as wn\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering the data\n",
    "\n",
    "The data is filtered to make it easier to work with. You can skip this part if you have already save the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>[investing, more, money, on, research, and, de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>[ralph, klein, was, a, bell, end, for, selling...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>[put, enough, efforts, ,, resources, and, comm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>[there, are, so, many, good, ideas, about, cle...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>[i, agree, ., i, live, in, a, small, town, abo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                               text\n",
       "0      1  [investing, more, money, on, research, and, de...\n",
       "1      0  [ralph, klein, was, a, bell, end, for, selling...\n",
       "2      0  [put, enough, efforts, ,, resources, and, comm...\n",
       "3      1  [there, are, so, many, good, ideas, about, cle...\n",
       "4      0  [i, agree, ., i, live, in, a, small, town, abo..."
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_excel('../ressources/generation-energy-idea-and-comment-submissions.xlsx', sheet_name=1, usecols=['Idea or Comment/Idée ou commentaire', 'Idea or Comment Description'])\n",
    "data.rename(columns = {'Idea or Comment/Idée ou commentaire':'label', 'Idea or Comment Description':'text'}, inplace = True)\n",
    "data['text'].dropna(inplace=True)\n",
    "data['text'] = data['text'].astype(str)\n",
    "data['text'] = [entry.lower() for entry in data['text']]\n",
    "data['text']= [word_tokenize(entry) for entry in data['text']] # break each entry in a set of words\n",
    "data['label'] = data['label'].apply(lambda x: 1 if x == \"Idea/Idée\" else 0)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lemmatizer and stop word\n",
    "\n",
    "Remove everything that is not a word or not relevant to the data.\n",
    "\n",
    "Source : https://medium.com/@bedigunjit/simple-guide-to-text-classification-nlp-using-svm-and-naive-bayes-with-python-421db3a72d34"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove Stop words, Non-Numeric and perfom Word Stemming/Lemmenting.\n",
    "# WordNetLemmatizer requires Pos tags to understand if the word is noun or verb or adjective etc. By default it is set to Noun\n",
    "tag_map = defaultdict(lambda : wn.NOUN)\n",
    "tag_map['J'] = wn.ADJ\n",
    "tag_map['V'] = wn.VERB\n",
    "tag_map['R'] = wn.ADV\n",
    "for index,entry in enumerate(data['text']):\n",
    "    # Declaring Empty List to store the words that follow the rules for this step\n",
    "    Final_words = []\n",
    "    # Initializing WordNetLemmatizer()\n",
    "    word_Lemmatized = WordNetLemmatizer()\n",
    "    # pos_tag function below will provide the 'tag' i.e if the word is Noun(N) or Verb(V) or something else.\n",
    "    for word, tag in pos_tag(entry):\n",
    "        # Below condition is to check for Stop words and consider only alphabets\n",
    "        if word not in stopwords.words('english') and word.isalpha():\n",
    "            word_Final = word_Lemmatized.lemmatize(word,tag_map[tag[0]])\n",
    "            Final_words.append(word_Final)\n",
    "    # The final processed set of words for each iteration will be stored in 'trainable_data'\n",
    "    data.loc[index,'trainable_data'] = str(Final_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert string of a list to list \n",
    "data['trainable_data'] = data['trainable_data'].apply(lambda x: eval(x))\n",
    "\n",
    "# assemble the list of words into a string\n",
    "data['trainable_data'] = data['trainable_data'].apply(lambda x: ' '.join(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('./ressources/data_cleaned.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('./ressources/data_cleaned.csv')\n",
    "data['trainable_data'] = data['trainable_data'].astype(str)\n",
    "reduced_data = data[0:400]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_train, sample_test, label_train, label_test = model_selection.train_test_split(reduced_data['trainable_data'], reduced_data['label'], train_size=0.80, test_size=0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "Encoder = LabelEncoder()\n",
    "Train_Y = Encoder.fit_transform(label_train)\n",
    "Test_Y = Encoder.fit_transform(label_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vectorizing the data\n",
    "\n",
    "For this part, the Bert model was tried, but we didn't achieve an accuracy similar to the base SVM since we had to reduce it to a vector of size 10. The Bert model gives a vector that would necessitate more than 700 qubits to work without data reduction. Because of this, we decide to switch and use an already existing method using sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tfidf_vect = TfidfVectorizer(max_features=10)\n",
    "Tfidf_vect.fit(data['trainable_data'])\n",
    "Train_X_Tfidf = Tfidf_vect.transform(sample_train)\n",
    "Test_X_Tfidf = Tfidf_vect.transform(sample_test)\n",
    "\n",
    "Train_X = Train_X_Tfidf.toarray()\n",
    "Test_X = Test_X_Tfidf.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the Quantum kernel\n",
    "\n",
    "Many kernel has been tested, but the one that can more easily give a quantum advantage is the ZZFeatureMap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zz feature map\n",
    "zz_map = ZZFeatureMap(feature_dimension=10, reps=1, entanglement='linear', insert_barriers=True)\n",
    "zz_kernel = QuantumKernel(feature_map=zz_map, quantum_instance=Aer.get_backend('statevector_simulator'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zz_circuit = zz_kernel.construct_circuit(Train_X[0], Train_X[1])\n",
    "zz_circuit.decompose().decompose().draw(output='mpl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QSVM Accuracy Score ->  67.50\n"
     ]
    }
   ],
   "source": [
    "zzcb_svc = SVC(kernel=zz_kernel.evaluate)\n",
    "zzcb_svc.fit(Train_X, label_train)\n",
    "zzcb_score = zzcb_svc.score(Test_X, label_test)\n",
    "\n",
    "print(\"QSVM Accuracy Score -> \",\"%.2f\" % (zzcb_score*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter tunning\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "depth : 59\n",
      "depth : 117\n",
      "depth : 175\n",
      "depth : 233\n",
      "depth : 291\n",
      "depth : 349\n",
      "depth : 407\n",
      "depth : 465\n",
      "depth : 523\n",
      "depth : 581\n",
      "depth : 639\n",
      "depth : 697\n",
      "depth : 755\n",
      "depth : 813\n",
      "depth : 871\n",
      "depth : 929\n",
      "depth : 987\n",
      "depth : 1045\n",
      "depth : 1103\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,20):\n",
    "    zz_map = ZZFeatureMap(feature_dimension=10, reps=i, entanglement='linear', insert_barriers=True)\n",
    "    zz_kernel = QuantumKernel(feature_map=zz_map, quantum_instance=Aer.get_backend('statevector_simulator'))\n",
    "    zz_circuit = zz_kernel.construct_circuit(Train_X[0], Train_X[1])\n",
    "    print(\"depth : \" + str(zz_circuit.decompose().decompose().depth()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QSVM Accuracy Score with 1reps ->  67.50\n",
      "QSVM Accuracy Score with 2reps ->  67.50\n",
      "QSVM Accuracy Score with 3reps ->  67.50\n",
      "QSVM Accuracy Score with 4reps ->  71.25\n",
      "QSVM Accuracy Score with 5reps ->  67.50\n",
      "QSVM Accuracy Score with 6reps ->  67.50\n",
      "QSVM Accuracy Score with 7reps ->  67.50\n",
      "QSVM Accuracy Score with 8reps ->  67.50\n",
      "QSVM Accuracy Score with 9reps ->  67.50\n",
      "QSVM Accuracy Score with 10reps ->  67.50\n",
      "QSVM Accuracy Score with 11reps ->  67.50\n",
      "QSVM Accuracy Score with 12reps ->  67.50\n",
      "QSVM Accuracy Score with 13reps ->  67.50\n",
      "QSVM Accuracy Score with 14reps ->  67.50\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,20):\n",
    "    zz_map = ZZFeatureMap(feature_dimension=10, reps=i, entanglement='linear', insert_barriers=True)\n",
    "    zz_kernel = QuantumKernel(feature_map=zz_map, quantum_instance=Aer.get_backend('statevector_simulator'))\n",
    "    zzcb_svc = SVC(kernel=zz_kernel.evaluate)\n",
    "    zzcb_svc.fit(Train_X, label_train)\n",
    "    zzcb_score = zzcb_svc.score(Test_X, label_test)\n",
    "\n",
    "    print(\"QSVM Accuracy Score with \" + str(i) + \" reps -> \",\"%.2f\" % (zzcb_score*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the depth is scaling linearly and the accuracy is increasing until 4 repetitions. If the speed is the main concern, doing only one or two repetitions of the kernel is good enough."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "To ascertain whether Quantum Support Vector Machines (QSVM) offer a competitive edge on industrial cases, it's essential to test them empirically. As of now, there's no definitive evidence proving whether QSVM can consistently outperform its classical SVM counterpart across various datasets."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('quantum')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "49c57e7cc00c6769ab79acd178159e44aa5ac48100986c29ef3d98880a98cdfe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
